{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise dos riscos das empresas entrarem em falencia\n",
    "\n",
    "**Objetivo**: Analisar os riscos de uma empresa entrar em falencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* `Industrial Risk (IR)`: Risco Industrial \n",
    "    - `0`: Positive\n",
    "    - `1`: Average\n",
    "    - `-1`: negative\n",
    "* `Management Risk (MR)`: Risco Industrial \n",
    "    - `0`: Positive\n",
    "    - `1`: Average\n",
    "    - `-1`: negative\n",
    "* `Financial Flexibility(FF)`: Risco Industrial \n",
    "    - `0`: Positive\n",
    "    - `1`: Average\n",
    "    - `-1`: negative\n",
    "* `Class`: Falencia/nao Falencia\n",
    "    - `0`: Bankruptcy\n",
    "    - `1`: Non-Bankruptcy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('data/Qualitative_Bankruptcy.csv') #chamando e abrindo o csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fazendo o tratamento dos dados\n",
    "feature_names = ['IR', 'MR', 'FF','Class']\n",
    "dados['IR'] = dados['IR'].map({'P': 0, 'A': 1, 'N':-1})\n",
    "dados['MR'] = dados['MR'].map({'P': 0, 'A': 1, 'N':-1})\n",
    "dados['FF'] = dados['FF'].map({'P': 0, 'A': 1, 'N':-1})\n",
    "dados['Class'] = dados['Class'].map({'B': 0, 'NB': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.dropna(subset=feature_names, inplace=True)\n",
    "\n",
    "X = dados[feature_names].to_numpy()\n",
    "y = dados['Class'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nomes dos Atributos:  ['IR', 'MR', 'FF', 'Class'] \n",
      "\n",
      "Tamanho de X:  (250, 4) \n",
      "\n",
      "Tamanho de y:  (250,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Nomes dos Atributos: ', feature_names, '\\n')\n",
    "print('Tamanho de X: ', X.shape, '\\n')\n",
    "print('Tamanho de y: ', y.shape, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quebrando dataset em `train` e `test`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho de X_train:  (187, 4) \n",
      "\n",
      "Tamanho de X_test:  (63, 4) \n",
      "\n",
      "Tamanho de y_train:  (187,) \n",
      "\n",
      "Tamanho de y_test:  (63,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Tamanho de X_train: ', X_train.shape, '\\n')\n",
    "print('Tamanho de X_test: ', X_test.shape, '\\n')\n",
    "print('Tamanho de y_train: ', y_train.shape, '\\n')\n",
    "print('Tamanho de y_test: ', y_test.shape, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo e Biblioteca Utilizados#\n",
    "\n",
    "No nosso projeto, utilizamos o modelo de Regressão Logistica, da biblioteca Sckit-Learn, pois este modelo apresentou a melhor acuracia nos testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss='log', learning_rate='constant', max_iter=100,\n",
    "                   eta0=0.0001, verbose=1, tol=None, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
      "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
      "              loss='log', max_iter=100, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='l2', power_t=0.5, random_state=123, shuffle=True,\n",
      "              tol=None, validation_fraction=0.1, verbose=1, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.01, NNZs: 4, Bias: 0.001741, T: 187, Avg. loss: 0.691419\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 4, Bias: 0.003464, T: 374, Avg. loss: 0.687892\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 4, Bias: 0.005172, T: 561, Avg. loss: 0.684399\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.03, NNZs: 4, Bias: 0.006864, T: 748, Avg. loss: 0.680940\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.04, NNZs: 4, Bias: 0.008538, T: 935, Avg. loss: 0.677513\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.05, NNZs: 4, Bias: 0.010196, T: 1122, Avg. loss: 0.674119\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.05, NNZs: 4, Bias: 0.011836, T: 1309, Avg. loss: 0.670758\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.06, NNZs: 4, Bias: 0.013460, T: 1496, Avg. loss: 0.667429\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.07, NNZs: 4, Bias: 0.015068, T: 1683, Avg. loss: 0.664132\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.08, NNZs: 4, Bias: 0.016660, T: 1870, Avg. loss: 0.660866\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.09, NNZs: 4, Bias: 0.018237, T: 2057, Avg. loss: 0.657632\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.09, NNZs: 4, Bias: 0.019797, T: 2244, Avg. loss: 0.654429\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.10, NNZs: 4, Bias: 0.021343, T: 2431, Avg. loss: 0.651256\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.11, NNZs: 4, Bias: 0.022872, T: 2618, Avg. loss: 0.648113\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.12, NNZs: 4, Bias: 0.024387, T: 2805, Avg. loss: 0.645000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.12, NNZs: 4, Bias: 0.025886, T: 2992, Avg. loss: 0.641916\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.13, NNZs: 4, Bias: 0.027370, T: 3179, Avg. loss: 0.638862\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.14, NNZs: 4, Bias: 0.028839, T: 3366, Avg. loss: 0.635836\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.15, NNZs: 4, Bias: 0.030293, T: 3553, Avg. loss: 0.632839\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.15, NNZs: 4, Bias: 0.031731, T: 3740, Avg. loss: 0.629871\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.16, NNZs: 4, Bias: 0.033156, T: 3927, Avg. loss: 0.626930\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.17, NNZs: 4, Bias: 0.034565, T: 4114, Avg. loss: 0.624017\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.17, NNZs: 4, Bias: 0.035960, T: 4301, Avg. loss: 0.621131\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.18, NNZs: 4, Bias: 0.037341, T: 4488, Avg. loss: 0.618273\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.19, NNZs: 4, Bias: 0.038707, T: 4675, Avg. loss: 0.615441\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.20, NNZs: 4, Bias: 0.040060, T: 4862, Avg. loss: 0.612635\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.20, NNZs: 4, Bias: 0.041400, T: 5049, Avg. loss: 0.609856\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.21, NNZs: 4, Bias: 0.042725, T: 5236, Avg. loss: 0.607102\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.22, NNZs: 4, Bias: 0.044036, T: 5423, Avg. loss: 0.604374\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.22, NNZs: 4, Bias: 0.045334, T: 5610, Avg. loss: 0.601671\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.23, NNZs: 4, Bias: 0.046619, T: 5797, Avg. loss: 0.598993\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.24, NNZs: 4, Bias: 0.047889, T: 5984, Avg. loss: 0.596340\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.24, NNZs: 4, Bias: 0.049147, T: 6171, Avg. loss: 0.593711\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.25, NNZs: 4, Bias: 0.050391, T: 6358, Avg. loss: 0.591107\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.26, NNZs: 4, Bias: 0.051622, T: 6545, Avg. loss: 0.588526\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.26, NNZs: 4, Bias: 0.052841, T: 6732, Avg. loss: 0.585969\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.27, NNZs: 4, Bias: 0.054047, T: 6919, Avg. loss: 0.583435\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.28, NNZs: 4, Bias: 0.055240, T: 7106, Avg. loss: 0.580924\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.28, NNZs: 4, Bias: 0.056420, T: 7293, Avg. loss: 0.578437\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.29, NNZs: 4, Bias: 0.057590, T: 7480, Avg. loss: 0.575971\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.30, NNZs: 4, Bias: 0.058748, T: 7667, Avg. loss: 0.573528\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.30, NNZs: 4, Bias: 0.059891, T: 7854, Avg. loss: 0.571107\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.31, NNZs: 4, Bias: 0.061024, T: 8041, Avg. loss: 0.568707\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.32, NNZs: 4, Bias: 0.062144, T: 8228, Avg. loss: 0.566330\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.32, NNZs: 4, Bias: 0.063252, T: 8415, Avg. loss: 0.563973\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.33, NNZs: 4, Bias: 0.064348, T: 8602, Avg. loss: 0.561638\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.34, NNZs: 4, Bias: 0.065434, T: 8789, Avg. loss: 0.559323\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.34, NNZs: 4, Bias: 0.066507, T: 8976, Avg. loss: 0.557029\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.35, NNZs: 4, Bias: 0.067569, T: 9163, Avg. loss: 0.554755\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.36, NNZs: 4, Bias: 0.068620, T: 9350, Avg. loss: 0.552501\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.36, NNZs: 4, Bias: 0.069660, T: 9537, Avg. loss: 0.550267\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.37, NNZs: 4, Bias: 0.070690, T: 9724, Avg. loss: 0.548053\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.38, NNZs: 4, Bias: 0.071707, T: 9911, Avg. loss: 0.545858\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.38, NNZs: 4, Bias: 0.072713, T: 10098, Avg. loss: 0.543682\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.39, NNZs: 4, Bias: 0.073710, T: 10285, Avg. loss: 0.541525\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.39, NNZs: 4, Bias: 0.074696, T: 10472, Avg. loss: 0.539387\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.40, NNZs: 4, Bias: 0.075670, T: 10659, Avg. loss: 0.537268\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.41, NNZs: 4, Bias: 0.076634, T: 10846, Avg. loss: 0.535167\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.41, NNZs: 4, Bias: 0.077588, T: 11033, Avg. loss: 0.533084\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.42, NNZs: 4, Bias: 0.078532, T: 11220, Avg. loss: 0.531019\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.43, NNZs: 4, Bias: 0.079466, T: 11407, Avg. loss: 0.528971\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.43, NNZs: 4, Bias: 0.080391, T: 11594, Avg. loss: 0.526941\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.44, NNZs: 4, Bias: 0.081305, T: 11781, Avg. loss: 0.524928\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.44, NNZs: 4, Bias: 0.082208, T: 11968, Avg. loss: 0.522933\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.45, NNZs: 4, Bias: 0.083103, T: 12155, Avg. loss: 0.520954\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.46, NNZs: 4, Bias: 0.083986, T: 12342, Avg. loss: 0.518992\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.46, NNZs: 4, Bias: 0.084861, T: 12529, Avg. loss: 0.517047\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.47, NNZs: 4, Bias: 0.085727, T: 12716, Avg. loss: 0.515118\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.47, NNZs: 4, Bias: 0.086584, T: 12903, Avg. loss: 0.513205\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.48, NNZs: 4, Bias: 0.087430, T: 13090, Avg. loss: 0.511308\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.48, NNZs: 4, Bias: 0.088269, T: 13277, Avg. loss: 0.509427\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.49, NNZs: 4, Bias: 0.089098, T: 13464, Avg. loss: 0.507561\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.50, NNZs: 4, Bias: 0.089918, T: 13651, Avg. loss: 0.505711\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.50, NNZs: 4, Bias: 0.090729, T: 13838, Avg. loss: 0.503876\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.51, NNZs: 4, Bias: 0.091531, T: 14025, Avg. loss: 0.502056\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.51, NNZs: 4, Bias: 0.092324, T: 14212, Avg. loss: 0.500252\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.52, NNZs: 4, Bias: 0.093110, T: 14399, Avg. loss: 0.498461\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.53, NNZs: 4, Bias: 0.093887, T: 14586, Avg. loss: 0.496686\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.53, NNZs: 4, Bias: 0.094655, T: 14773, Avg. loss: 0.494925\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.54, NNZs: 4, Bias: 0.095414, T: 14960, Avg. loss: 0.493178\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.54, NNZs: 4, Bias: 0.096165, T: 15147, Avg. loss: 0.491445\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.55, NNZs: 4, Bias: 0.096909, T: 15334, Avg. loss: 0.489726\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.55, NNZs: 4, Bias: 0.097644, T: 15521, Avg. loss: 0.488021\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.56, NNZs: 4, Bias: 0.098371, T: 15708, Avg. loss: 0.486330\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.56, NNZs: 4, Bias: 0.099091, T: 15895, Avg. loss: 0.484652\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.57, NNZs: 4, Bias: 0.099802, T: 16082, Avg. loss: 0.482988\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.58, NNZs: 4, Bias: 0.100505, T: 16269, Avg. loss: 0.481336\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.58, NNZs: 4, Bias: 0.101201, T: 16456, Avg. loss: 0.479698\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 0.59, NNZs: 4, Bias: 0.101889, T: 16643, Avg. loss: 0.478072\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 0.59, NNZs: 4, Bias: 0.102570, T: 16830, Avg. loss: 0.476460\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 0.60, NNZs: 4, Bias: 0.103242, T: 17017, Avg. loss: 0.474860\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 0.60, NNZs: 4, Bias: 0.103908, T: 17204, Avg. loss: 0.473272\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 0.61, NNZs: 4, Bias: 0.104566, T: 17391, Avg. loss: 0.471697\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 0.61, NNZs: 4, Bias: 0.105217, T: 17578, Avg. loss: 0.470134\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 0.62, NNZs: 4, Bias: 0.105861, T: 17765, Avg. loss: 0.468583\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 0.62, NNZs: 4, Bias: 0.106498, T: 17952, Avg. loss: 0.467044\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 0.63, NNZs: 4, Bias: 0.107129, T: 18139, Avg. loss: 0.465517\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 0.63, NNZs: 4, Bias: 0.107752, T: 18326, Avg. loss: 0.464001\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 0.64, NNZs: 4, Bias: 0.108368, T: 18513, Avg. loss: 0.462498\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 0.65, NNZs: 4, Bias: 0.108977, T: 18700, Avg. loss: 0.461005\n",
      "Total training time: 0.06 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=100, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=123, shuffle=True,\n",
       "              tol=None, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acurácia do Modelo\n",
    "Usar a função do Scikit-Learn [`sklearn.metrics.accuracy_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "\n",
    "Retorna um score de acurácia `float` entre $0$ e $1$\n",
    "\n",
    "#### Argumentos\n",
    "* `y_true`: Classes Verdadeiras\n",
    "    * 2 classes: vetor (1-D)\n",
    "    * Mais que 2 classes: matriz (2-D)\n",
    "* `y_pred`: Classes Previstas pelo Modelo\n",
    "    * 2 classes: vetor (1-D)\n",
    "    * Mais que 2 classes: matriz (2-D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IR: 0.083\n",
      "MR: 0.132\n",
      "FF: 0.433\n",
      "Class: 0.452\n",
      "Constante: [0.10897664]\n"
     ]
    }
   ],
   "source": [
    "# Coeficientes do modelo\n",
    "for feature, coef in zip(feature_names, clf.coef_[0].tolist()):\n",
    "    print(f\"{feature}: {round(coef,3)}\")\n",
    "\n",
    "# Constante do modelo\n",
    "print(f\"Constante: {clf.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia de Treino: 0.97861\n",
      "\n",
      " ---------------------------\n",
      "\n",
      "Acurácia de Teste: 0.96825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_train_true = y_train\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_true = y_test\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"Acurácia de Treino: {round(accuracy_score(y_train_true, y_train_pred), 5)}\")\n",
    "print('\\n ---------------------------\\n')\n",
    "print(f\"Acurácia de Teste: {round(accuracy_score(y_test_true, y_test_pred), 5)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
